{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-05T03:49:45.863818Z",
     "start_time": "2024-08-05T03:49:43.219052Z"
    }
   },
   "source": [
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecMonitor\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.0 (SDL 2.28.4, Python 3.8.19)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T03:49:46.256273Z",
     "start_time": "2024-08-05T03:49:45.863818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import the custom environment and wrapper\n",
    "from custom_env import CustomEnv\n",
    "from wrappers import FullyObsSB3MLPWrapper"
   ],
   "id": "a677bf4489cac1f5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13769\\anaconda3\\envs\\mini-grid-generation\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\13769\\anaconda3\\envs\\mini-grid-generation\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\13769\\anaconda3\\envs\\mini-grid-generation\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T03:49:46.271859Z",
     "start_time": "2024-08-05T03:49:46.256273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the session directory\n",
    "session_dir = \"small_corridor\"\n",
    "os.makedirs(session_dir, exist_ok=True)\n",
    "\n",
    "# Set the log directory within the session directory\n",
    "log_dir = os.path.join(session_dir, \"logs\")\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Set training parameters\n",
    "total_timesteps = int(1e5)\n",
    "check_freq = int(1e3)\n",
    "model_save_path = os.path.join(session_dir, \"latest_model\")"
   ],
   "id": "7b4d8c9df8b34ed9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T03:49:46.287897Z",
     "start_time": "2024-08-05T03:49:46.271859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the environment and wrapper\n",
    "env = CustomEnv(\n",
    "    txt_file_path='simple_test_corridor.txt',\n",
    "    display_size=6,\n",
    "    display_mode=\"random\",\n",
    "    random_rotate=True,\n",
    "    random_flip=True,\n",
    "    custom_mission=\"Find the key and open the door.\",\n",
    ")\n",
    "env = FullyObsSB3MLPWrapper(env)"
   ],
   "id": "1c4bbb011ff1ae53",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T03:49:49.144365Z",
     "start_time": "2024-08-05T03:49:46.287897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load or create a new model\n",
    "if os.path.exists(f\"{model_save_path}.zip\"):\n",
    "    model = PPO.load(model_save_path, env=env)\n",
    "    print(\"Loaded model from saved path.\")\n",
    "else:\n",
    "    model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "    print(\"Initialized new model.\")"
   ],
   "id": "3f367c40f04afe7b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Initialized new model.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T03:49:49.154365Z",
     "start_time": "2024-08-05T03:49:49.144365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize TensorBoard writer\n",
    "writer = SummaryWriter(log_dir)\n",
    "# Create evaluation callback\n",
    "eval_callback = EvalCallback(\n",
    "    env,\n",
    "    best_model_save_path=best_model_save_path,\n",
    "    log_path=log_dir,\n",
    "    eval_freq=eval_freq,\n",
    "    deterministic=True,\n",
    "    render=False\n",
    ")\n",
    "\n",
    "# Create checkpoint callback\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "    save_freq=save_freq,\n",
    "    save_path=session_dir,\n",
    "    name_prefix=\"rl_model\",\n",
    "    verbose=1\n",
    ")\n"
   ],
   "id": "cde816fe9d568a1",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T03:49:52.648232Z",
     "start_time": "2024-08-05T03:49:49.154365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the model and log performance\n",
    "try:\n",
    "    for i in range(total_timesteps // check_freq):\n",
    "        # Train the model for a specified number of timesteps\n",
    "        model.learn(total_timesteps=check_freq, callback=callback)\n",
    "        \n",
    "        # Evaluate the model and log performance metrics\n",
    "        mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "        writer.add_scalar(\"Evaluation/Mean Reward\", mean_reward, i * check_freq)\n",
    "        writer.add_scalar(\"Evaluation/Std Reward\", std_reward, i * check_freq)\n",
    "\n",
    "        # Save the latest model\n",
    "        model.save(model_save_path)\n",
    "        print(f\"Model saved at timestep {i * check_freq}.\")\n",
    "finally:\n",
    "    # Ensure that the TensorBoard writer is closed properly\n",
    "    writer.close()"
   ],
   "id": "f2109d7ba111bfec",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13769\\anaconda3\\envs\\mini-grid-generation\\lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001B[33mWARN: env.ep_info_buffer to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.ep_info_buffer` for environment variables or `env.get_wrapper_attr('ep_info_buffer')` that will search the reminding wrappers.\u001B[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CustomEnv' object has no attribute 'ep_info_buffer'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(total_timesteps \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m check_freq):\n\u001B[0;32m      4\u001B[0m         \u001B[38;5;66;03m# Train the model for a specified number of timesteps\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m         \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheck_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m         \u001B[38;5;66;03m# Evaluate the model and log performance metrics\u001B[39;00m\n\u001B[0;32m      8\u001B[0m         mean_reward, std_reward \u001B[38;5;241m=\u001B[39m evaluate_policy(model, env, n_eval_episodes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\mini-grid-generation\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:315\u001B[0m, in \u001B[0;36mPPO.learn\u001B[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001B[0m\n\u001B[0;32m    306\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlearn\u001B[39m(\n\u001B[0;32m    307\u001B[0m     \u001B[38;5;28mself\u001B[39m: SelfPPO,\n\u001B[0;32m    308\u001B[0m     total_timesteps: \u001B[38;5;28mint\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    313\u001B[0m     progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    314\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m SelfPPO:\n\u001B[1;32m--> 315\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    316\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    317\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    318\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlog_interval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog_interval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    319\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtb_log_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtb_log_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    320\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    321\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    322\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\mini-grid-generation\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:300\u001B[0m, in \u001B[0;36mOnPolicyAlgorithm.learn\u001B[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001B[0m\n\u001B[0;32m    297\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menv \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    299\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_timesteps \u001B[38;5;241m<\u001B[39m total_timesteps:\n\u001B[1;32m--> 300\u001B[0m     continue_training \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollect_rollouts\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrollout_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_rollout_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_steps\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    302\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m continue_training:\n\u001B[0;32m    303\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\mini-grid-generation\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:201\u001B[0m, in \u001B[0;36mOnPolicyAlgorithm.collect_rollouts\u001B[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001B[0m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;66;03m# Give access to local variables\u001B[39;00m\n\u001B[0;32m    200\u001B[0m callback\u001B[38;5;241m.\u001B[39mupdate_locals(\u001B[38;5;28mlocals\u001B[39m())\n\u001B[1;32m--> 201\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mcallback\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    202\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_info_buffer(infos, dones)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\mini-grid-generation\\lib\\site-packages\\stable_baselines3\\common\\callbacks.py:114\u001B[0m, in \u001B[0;36mBaseCallback.on_step\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_calls \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_timesteps \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mnum_timesteps\n\u001B[1;32m--> 114\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_on_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\workspace\\mini-grid-generation\\callbacks.py:25\u001B[0m, in \u001B[0;36mSaveOnBestTrainingRewardCallback._on_step\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_on_step\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;66;03m# Check every check_freq steps\u001B[39;00m\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_calls \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_freq \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m     23\u001B[0m         \u001B[38;5;66;03m# Retrieve the latest episode rewards from the VecMonitor wrapper\u001B[39;00m\n\u001B[0;32m     24\u001B[0m         \u001B[38;5;66;03m# VecMonitor automatically collects episode rewards and lengths\u001B[39;00m\n\u001B[1;32m---> 25\u001B[0m         episode_rewards \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_env\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_attr\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mep_info_buffer\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     27\u001B[0m         \u001B[38;5;66;03m# Flatten the list of episode information from each environment\u001B[39;00m\n\u001B[0;32m     28\u001B[0m         episode_rewards \u001B[38;5;241m=\u001B[39m [info[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m infos \u001B[38;5;129;01min\u001B[39;00m episode_rewards \u001B[38;5;28;01mfor\u001B[39;00m info \u001B[38;5;129;01min\u001B[39;00m infos]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\mini-grid-generation\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:395\u001B[0m, in \u001B[0;36mVecEnvWrapper.get_attr\u001B[1;34m(self, attr_name, indices)\u001B[0m\n\u001B[0;32m    394\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_attr\u001B[39m(\u001B[38;5;28mself\u001B[39m, attr_name: \u001B[38;5;28mstr\u001B[39m, indices: VecEnvIndices \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[Any]:\n\u001B[1;32m--> 395\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvenv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_attr\u001B[49m\u001B[43m(\u001B[49m\u001B[43mattr_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\mini-grid-generation\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:118\u001B[0m, in \u001B[0;36mDummyVecEnv.get_attr\u001B[1;34m(self, attr_name, indices)\u001B[0m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Return attribute from vectorized environment (see base class).\"\"\"\u001B[39;00m\n\u001B[0;32m    117\u001B[0m target_envs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_target_envs(indices)\n\u001B[1;32m--> 118\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28mgetattr\u001B[39m(env_i, attr_name) \u001B[38;5;28;01mfor\u001B[39;00m env_i \u001B[38;5;129;01min\u001B[39;00m target_envs]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\mini-grid-generation\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:118\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Return attribute from vectorized environment (see base class).\"\"\"\u001B[39;00m\n\u001B[0;32m    117\u001B[0m target_envs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_target_envs(indices)\n\u001B[1;32m--> 118\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43menv_i\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattr_name\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m env_i \u001B[38;5;129;01min\u001B[39;00m target_envs]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\mini-grid-generation\\lib\\site-packages\\gymnasium\\core.py:315\u001B[0m, in \u001B[0;36mWrapper.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m    310\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maccessing private attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is prohibited\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    311\u001B[0m logger\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    312\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124menv.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m to get variables from other wrappers is deprecated and will be removed in v1.0, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    313\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mto get this variable you can do `env.unwrapped.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` for environment variables or `env.get_wrapper_attr(\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m)` that will search the reminding wrappers.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    314\u001B[0m )\n\u001B[1;32m--> 315\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'CustomEnv' object has no attribute 'ep_info_buffer'"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
